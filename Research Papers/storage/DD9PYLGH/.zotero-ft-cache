medRxiv preprint doi: https://doi.org/10.1101/2020.02.14.20023028.this version posted April 24, 2020. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission.

1 A deep learning algorithm using CT images to screen for Corona Virus

2

Disease (COVID-19)

3 Shuai Wang1,*, Bo Kang2,3,*, Jinlu Ma4,*, Xianjun Zeng5,*, Mingming Xiao1,*, Jia

4 Guo3, Mengjiao Cai4, Jingyi Yang4, Yaodong Li6, Xiangfei Meng2,#, Bo Xu1,#

5
6 1 Department of Molecular Radiation Oncology, National Clinical Research Center
7 for Cancer, Key Laboratory of Cancer Prevention and Therapy, Key Laboratory of
8 Breast Cancer Prevention and Therapy, Ministry of Education, Tianjin Clinical
9 Research Center for Cancer, Tianjin Medical University Cancer Institute and
10 Hospital, Tianjin 300060, China 11 2 College of Intelligence and Computing, Tianjin University, Tianjin 300350, China 12 3 National Supercomputer Center in Tianjin, Tianjin 300457, China 13 4 Department of Radiation Oncology, First Affiliated Hospital, Xi’an Jiaotong
14 University, Xi’an, China 15 5 Department of Radiology, Nanchang University First Hospital, Nanchang, China 16 6 Department of Radiology, No.8 Hospital, Xi’an Medical College, Xi’an, China
17 * Equal contribution
18 # Corresponding authors:
19 Bo Xu, MD, PhD 20 Tianjin Medical University Cancer Institute and Hospital 21 Tianjin 300060, China 22 Email: xubo@tmu.edu.cn
23
24 Xiangfei Meng, PhD 25 National Supercomputer Center in Tianjin 26 Tianjin 300457, China 27 Email: mengxf@nscc-tj.cn
28

1

medRxiv preprint doi: https://doi.org/10.1101/2020.02.14.20023028.this version posted April 24, 2020. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission.

29

Abstract

30

Background: The outbreak of Severe Acute Respiratory Syndrome Coronavirus

31 2 (SARS-COV-2) has caused more than 2.5 million cases of Corona Virus Disease

32 (COVID-19) in the world so far, with that number continuing to grow. To control the

33 spread of the disease, screening large numbers of suspected cases for appropriate

34 quarantine and treatment is a priority. Pathogenic laboratory testing is the gold

35 standard but is time-consuming with significant false negative results. Therefore,

36 alternative diagnostic methods are urgently needed to combat the disease. Based

37 on COVID-19 radiographical changes in CT images, we hypothesized that Artificial

38 Intelligence’s deep learning methods might be able to extract COVID-19’s specific

39 graphical features and provide a clinical diagnosis ahead of the pathogenic test, thus

40 saving critical time for disease control.

41

Methods and Findings: We collected 1,065 CT images of pathogen-confirmed

42 COVID-19 cases (325 images) along with those previously diagnosed with typical

43 viral pneumonia (740 images). We modified the Inception transfer-learning model to

44 establish the algorithm, followed by internal and external validation. The internal

45 validation achieved a total accuracy of 89.5% with specificity of 0.88 and sensitivity

46 of 0.87. The external testing dataset showed a total accuracy of 79.3% with

47 specificity of 0.83 and sensitivity of 0.67. In addition, in 54 COVID-19 images that

48 first two nucleic acid test results were negative, 46 were predicted as COVID-19

49 positive by the algorithm, with the accuracy of 85.2%.

50

Conclusion: These results demonstrate the proof-of-principle for using

51 artificial intelligence to extract radiological features for timely and accurate
2

medRxiv preprint doi: https://doi.org/10.1101/2020.02.14.20023028.this version posted April 24, 2020. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission.

52 COVID-19 diagnosis.

53

Author summary

54

To control the spread of the COVID-19, screening large numbers of suspected

55 cases for appropriate quarantine and treatment measures is a priority. Pathogenic

56 laboratory testing is the gold standard but is time-consuming with significant false

57 negative results. Therefore, alternative diagnostic methods are urgently needed to

58 combat the disease. We hypothesized that Artificial Intelligence’s deep learning

59 methods might be able to extract COVID-19’s specific graphical features and

60 provide a clinical diagnosis ahead of the pathogenic test, thus saving critical time.

61 We collected 1,065 CT images of pathogen-confirmed COVID-19 cases along with

62 those previously diagnosed with typical viral pneumonia. We modified the Inception

63 transfer-learning model to establish the algorithm. The internal validation achieved

64 a total accuracy of 89.5% with specificity of 0.88 and sensitivity of 0.87. The

65 external testing dataset showed a total accuracy of 79.3% with specificity of 0.83

66 and sensitivity of 0.67. In addition, in 54 COVID-19 images that first two nucleic

67 acid test results were negative, 46 were predicted as COVID-19 positive by the

68 algorithm, with the accuracy of 85.2%. Our study represents the first study to apply

69 artificial intelligence to CT images for effectively screening for COVID-19.

70

Keywords: COVID-19, Computed Tomography, Artificial Intelligence, Deep

71 Learning, Diagnosis

3

medRxiv preprint doi: https://doi.org/10.1101/2020.02.14.20023028.this version posted April 24, 2020. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission.

72

Introduction

73

The outbreak of atypical and person-to-person transmissible pneumonia

74 caused by the severe acute respiratory syndrome coronavirus 2 (SARS-COV-2,

75 also known as 2019-nCov) has caused a global alarm. There have been more

76 than 2.5 million confirmed cases of the Corona Virus Disease (COVID-19) in 77 the world, as of April 23, 2020. About 16-21% of people with the virus in China 78 have become severely ill with a 2-3% mortality rate. With the most recent

79 estimated viral reproduction number (R0), the average number of other people 80 that an infected individual will transmit the virus to in a completely non-immune 81 population, stands at about 3.77 [1], indicating that a rapid spread of the

82 disease is imminent. It is crucial to identify infected individuals as early as 83 possible for quarantine and treatment procedures.

84

The diagnosis of COVID-19 relies on the following criteria: clinical

85 symptoms, epidemiological history and positive CT images, as well as positive 86 pathogenic testing. The clinical characteristics of COVID-19 include respiratory

87 symptoms, fever, cough, dyspna, and pneumonia [3-6]. However, these

88 symptoms are nonspecific, as there are isolated cases where, for example, in 89 an asymptomatic infected family a chest CT scan revealed pneumonia and the

90 pathogenic test for the virus came back positive. Once someone is identified

91 as a PUI (person under investigation), lower respiratory specimens, such as 92 bronchoalveolar lavage, tracheal aspirate or sputum, will be collected for

93 pathogenic testing. This laboratory technology is based on real-time RT-PCR

4

medRxiv preprint doi: https://doi.org/10.1101/2020.02.14.20023028.this version posted April 24, 2020. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission.

94 and sequencing of nucleic acid from the virus [7,8]. Since the beginning of the

95 outbreak, the efficiency of nucleic acid testing has been dependent on several 96 rate-limiting factors, including availability and quantity of the testing kits in the 97 affected area. More importantly, the quality, stability and reproducibility of the

98 detection kits are questionable. The impact of methodology, disease stages, 99 specimen collection methods, nucleic acid extraction methods, and the 100 amplification system are all determinant factors for the accuracy of test results.

101 Conservative estimates of the detection rate of nucleic acid are low (between 102 30-50%) [7,8,9], and tests need to be repeated several times in many cases 103 before they can be confirmed.

104

Radiological imaging is also a major diagnostic tool for COVID-19. The

105 majority of COVID-19 cases have similar features on CT images including

106 ground-glass opacities in the early stage and pulmonary consolidation in the

107 late stage. There is also sometimes a rounded morphology and a peripheral 108 lung distribution [6,10]. Although typical CT images may help early screening

109 of suspected cases, the images of various viral pneumonias are similar and

110 they overlap with other infectious and inflammatory lung diseases. Therefore, it 111 is difficult for radiologists to distinguish COVID-19 from other viral pneumonias.

112

Artificial Intelligence involving medical imaging deep-learning systems has

113 been developed in image feature extraction, including shape and spatial 114 relation features. Specifically, Convolutional Neural Network (CNN) has been

115 proven in feature extraction and learning. CNN was used to enhance low-light

5

medRxiv preprint doi: https://doi.org/10.1101/2020.02.14.20023028.this version posted April 24, 2020. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission.

116 images from high-speed video endoscopy with the limited training data being

117 just 55 videos [11]. Also, CNN has been applied to identify the nature of 118 pulmonary nodules via CT images, the diagnosis of pediatric pneumonia via 119 chest X-ray images, automated precising and labeling of polyps during

120 colonoscopic videos, cystoscopic image recognition extraction from videos

121 [12-15].

122

There are a number of features for identifying viral pathogens on the basis

123 of imaging patterns, which are associated with their specific pathogenesis [16]. 124 The hallmarks of COVID-19 are bilateral distribution of patchy shadows and 125 ground glass opacity in early stages. As the disease progresses, multiple

126 ground glass and infiltrates in both lungs will appear [3]. Theses features are 127 quite similar to typical viral pneumonia with only slight differences, which are

128 difficult to be distinguished by radiologists. Based on this, we believed that

129 CNN might help us identify unique features that might be difficult for visual 130 recognition.

131 Hence, the purpose of our study was to evaluate the diagnostic performance of

132 a deep learning algorithm using CT images to screen for COVID-19 during the 133 influenza season. To test this notion, we retrospectively enrolled 1,065 CT

134 images of pathogen-confirmed COVID-19 cases along with previously

135 diagnosed typical viral pneumonia. Our results reported below demonstrate 136 the proof-of-principle using the deep learning method to extract radiological

137 graphical features for COVID-19 diagnosis.

6

medRxiv preprint doi: https://doi.org/10.1101/2020.02.14.20023028.this version posted April 24, 2020. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission.

138

Methods and Materials

139

Retrospective collection of datasets.

140

We retrospectively collected CT images from 259 patients, in which the

141 cohort includes 180 cases of typical viral pneumonia and the other 79 cases

142 from three hospitals with confirmed nucleic acid testing of SARS-COV-2. In

143 addition, we enrolled additional 15 COVID cases, in which first two nucleic acid

144 tests were negative at initial diagnoses. Hospitals providing the images were

145 Xi’an Jiaotong University First Affiliated Hospital (Center 1), Nanchang

146 University First Hospital (Center 2) and Xi’an No.8 Hospital of Xi’an Medical

147 College (Center 3). All CT images were de-identified before sending for

148 analysis. This study is in compliance with the Institutional Review Board of

149 each participating institutes. Informed consent was exempted by the IRB

150 because of the retrospective nature of this study.

151

Delineation of ROIs

152

To establish a binary model for distinguishing COVID-19 and typical

153 pneumonia, we drew the Region of Interest (ROI) as input images for the

154 training cohort and validation cohorts. We sketched the ROI from CT images

155 based on features of COVID-19, such as small patchy shadows and interstitial

156 changes in the early stage, multiple ground glass and infiltrates in both lungs in

157 the progression stage, and delineated the ROIs on the CT images of other

158 typical viral pneumonia such as pseudocavity, enlarged lymphnodes and

159 multifocal GGO as the control. The ROIs were divided into three cohorts: one

160 training cohort (n=320 from Center 1), one internal validation cohort (n=455
7

medRxiv preprint doi: https://doi.org/10.1101/2020.02.14.20023028.this version posted April 24, 2020. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission.

161 from Center 1) and one external validation cohort (n=290 from Center 2 and 3).

162 For a ROI, it is sized approximately from 395*223 to 636*533 pixels.

163

Overview of the proposed architecture

164

Our systematic pipeline for the prediction architecture is depicted in Fig 1.

165 The architecture consists of three main processes: 1) Pre-processing of input

166 images; 2) Feature extraction of ROI images and training; and 3) Classification

167 with fully connected network and prediction of multiple classifiers. We built a

168 transfer learning neural network based on the Inception network. The entire

169 neural network can be roughly divided into two parts: the first part used a

170 pre-trained inception network to convert image data into one-dimensional

171 feature vectors, and the second part used a fully connected network and the

172 main role is for classification prediction. ROI images from each case were

173 preprocessed and inputted into the model for training. The number of various

174 types of pictures in the training set is equal, with a total number of 320. The

175 remaining CT pictures of each case were used for internal validation. The

176 model training was iterated 15,000 times with a step size of 0.01.

177

178
179 Fig 1. ROI images extraction and Deep Learning (DL) algorithm framework.
8

medRxiv preprint doi: https://doi.org/10.1101/2020.02.14.20023028.this version posted April 24, 2020. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission.

180 ROI images were extracted by the CV model and then trained using a modified

181 Inception network to extract features. The full connection layer then makes a

182 classification and prediction.

183

Image preprocessing and feature extraction

184

Based on the signs of characteristic of pneumonia, ROI images were

185 defined inflammatory lesions and extracted by our computer vision (CV) model

186 following the steps. 1) Convert the image to grayscale. 2) Binarize grayscale.

187 Because using the OSTU’s method directly may cause the threshold selection

188 failure in the case of multi-peaks, the selection of the binarization threshold in

189 this paper was based on the statistics of all pixel frequency histograms of the

190 gray color values Vmin (80) and Vmax (200). The minimum frequency in the

191 selection interval is threshold, and the interval of frequency statistics is five. 3)

192 Background area filling. Using the flood filling method to expand the image by

193 1 black pixel, and fill the black pixels near the border with white. 4) Reverse

194 color, find all the contour areas of the image, and keep the two largest contour

195 areas as the two lung areas. 5) Take the smallest bounding rectangle of the

196 lung area as the ROI frame and crop the original image to obtain the ROI

197 images. The delineated ROIs were obtained for classification model building.

198 We modified the typical Inception network, and fine-tuned the modified

199 Inception (M-Inception) model with pre-trained weights. During the training

200 phase, the original Inception part was not trained, and we only trained the

201 modified part. The architecture of M-Inception is shown in Table 1. The

9

medRxiv preprint doi: https://doi.org/10.1101/2020.02.14.20023028.this version posted April 24, 2020. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission.

202 difference between Inception and M-Inception in classification lies in the last

203 fully-connected layers. We reduced the dimension of features before it was

204 sent to the final classification layer. The training dataset made up of all those

205 patches aforementioned. The Inception network is shown in Table 1.

206

Table 1. The architecture of M-Inception

Layer

Patch size/stride or remarks

conv

3×3/2

conv

3×3/1

conv padded 3×3/1

Inception part

pool onv conv

3×3/2 3×3/1 3×3/2

conv

3×3/1

Inception

3x, 5x, 2x

pool

8x8

linear

logits

softmax

classifier

Fc1 Modified

part

Fc2

batchnorm [dropout(0.5)]
512d Linear
batchnorm [dropout(0.5)]
2d Linear

207

208

Prediction.

10

medRxiv preprint doi: https://doi.org/10.1101/2020.02.14.20023028.this version posted April 24, 2020. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission.

209

After generating the features, the final step was to classify the pneumonia

210 based on those features. Ensembling of classifiers was used to improve the

211 classification accuracy. In this study, we adopted end-to-end learning to make

212 the model convergence.

213

Performance evaluation metrics.

214

We compared the classification performance using Accuracy, Sensitivity,

215 Specificity, Area Under Curve (AUC), Positive predictive value (PPV), Negative

216 predictive value (NPV), F1 score and Youden Index. TP and TN represent the

217 number of true positive or true negative samples. FP and FN mean the number

218 of false positive or false negative samples. Sensitivity measures the ratio of

219 positives that are correctly discriminated. Specificity measures the ratio of

220 negatives that are correctly discriminated. AUC is an index to measure the

221 performance of the classifier. NPV was used to evaluate the algorithm for

222 screening, and PPV was the probability of getting a disease when the

223 diagnostic index is positive. Youden Index was the determining exponent of the

224 optimal bound. F1 score was a measure of the accuracy of a binary model.

225 Additionally, performance was evaluated with F-measure (F1) to compare the

226 similarity and diversity of performance. Kappa value measures the agreement

227 between the CNN model prediction and the clinical report.
228

11

medRxiv preprint doi: https://doi.org/10.1101/2020.02.14.20023028.this version posted April 24, 2020. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission.

229

Results

230

Algorithm development.

231

In order to develop a deep learning algorithm for the identification of viral

232 pneumonia images, we initially enrolled 259 patients, in which the cohort

233 includes 180 cases of typical viral pneumonia that were diagnosed previously

234 before the COVID-19 outbreak. These patients are termed COVID-19 negative

235 in the cohort. The other 79 cases were from the three hospitals with confirmed

236 nucleic acid testing of SARS-COV-2, therefore termed COVID-19 positive. Two

237 radiologists were asked to review the images and sketched 1,065

238 representative images (740 for COVID-19 negative and 325 for COVID-19

239 positive) for analysis (Fig 2 is shown as an example). These images were

240 randomly divided into a training set and a validation set. The model training

241 was iterated for 15,000 times with a step size of 0.01. The training loss curve is

242 shown in Fig 3A. 320 images (160 images from COVID-19 negative and 160

243 images from COVID-19 positive) were obtained to construct the model. To test

244 the stability and generalization of the model, 455 images (COVID-19 ngegative

245 360 images and COVID-19 positive 95 images) were obtained for internal

246 validation from Center 1 and 290 images (COVID-19 negative 220 images and

247 COVID-19 positive 70 images) were obtained from Center 2 and 3 for external

248 validation. The model training was also iterated for 15,000 times with a step

249 size of 0.01. The training loss curve is shown in Fig 3B.

12

medRxiv preprint doi: https://doi.org/10.1101/2020.02.14.20023028.this version posted April 24, 2020. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission.
250
251 Fig 2. An example of COVID-19 pneumonia features. The blue arrow points to 252 ground-glass opacity, and the yellow arrow points to the pleural indentation 253 sign.
254
13

medRxiv preprint doi: https://doi.org/10.1101/2020.02.14.20023028.this version posted April 24, 2020. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission.

255
256 Fig 3. Training loss curves of the models on internal (A) and external (B) 257 validation. The loss curve tends to be stable after descending, indicating that

258 the training process converges

259

Deep learning performance.

260

The deep learning algorithm yielded an AUC of 0.93 (95% CI, 0.90 to 0.96)

261 on the internal validation and 0.81 (95% CI, 0.71 to 0.84) on the external

262 validation based on the certain CT images (Fig 4). Using the maximized 263 Youden index threshold probability, the sensitivity was 0.88 and 0.83,

14

medRxiv preprint doi: https://doi.org/10.1101/2020.02.14.20023028.this version posted April 24, 2020. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission.
264 specificity 0.87 and 0.67, the accuracy 89.5% and 79.3%, the negative 265 prediction values 0.95 and 0.90, the Youden indexes 0.75 and 0.48, and the F1 266 scores were 0.77 and 0.63 for the internal and external datasets, respectively 267 (Table 2). The kappa values were 0.69 and 0.48 for internal and external 268 validation in certain CT images, indicating that prediction of COVID-19 from 269 the CNN model is a highly consistent with pathogenic testing results. We also 270 performed an external validation based on each patient’s multiple images. The 271 accuracy was 82.5%, the sensitivity 0.75, the specificity 0.86, the PPV 0.69, 272 the NPV 0.89, and the kappa value was 0.59.
15

medRxiv preprint doi: https://doi.org/10.1101/2020.02.14.20023028.this version posted April 24, 2020. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission.
273
274 Fig 4. Receiver operating characteristic plots for COVID-19 identification for 275 the deep learning (Inception) algorithm. (A) Internal Validation. (B) External 276 Validation.
277
16

medRxiv preprint doi: https://doi.org/10.1101/2020.02.14.20023028.this version posted April 24, 2020. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission.

278

Table 2. Deep learning Algorithm Performance

Performance Metric

Internal

External

AUC（95%CI） Accuracy, % Sensitivity Specificity PPV NPV Kappa Yoden index F1 scoreǂ

0.93(0.86 to 0.94) 89.5 0.88 0.87 0.71 0.95 0.69 0.75 0.77

0.81(0.71 to 0.84) 79.3 0.83 0.67 0.55 0.90 0.48 0.50 0.63

279  Measures the agreement between the CNN model prediction and the clinical

280 diagnosis. ǂMeasures the accuracy of the CNN model.

281

282

Comparison of AI with radiologist prediction.

283

At the same time, we asked two skilled radiologists to assess the 745

284 images for a prediction. Radiologist 1 achieved the accuracy of 55.8% with

285 sensitivity of 0.71 and specificity of 0.51, and Radiologist 2 achieved a similar

286 accuracy of 55.4% with sensitivity of 0.73 and specificity of 0.50 (Table 3).

287 These results indicates that it is difficult for radiologists to make prediction of

288 COVID-19 with eye recognition, further showing the advantage of the

289 algorithm we developed.

290

291

292
17

medRxiv preprint doi: https://doi.org/10.1101/2020.02.14.20023028.this version posted April 24, 2020. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission.

293

Table 3. Performance metrics for the CNN model versus skilled

294

radiologists.

External

External

Performance Internal (Based on (Based on

Metric

ROI)

patients)

R1

R2

Accuracy, % 89.5

79.3

82.5

55.8

55.4

Sensitivity

0.88

0.83

0.75

0.71

0.73

Specificity

0.87

0.67

0.86

0.51

0.5

PPV

0.71

0.55

0.69

0.29

0.29

NPV

0.95

0.90

0.89

0.86

0.86

F1 score

0.77

0.63

0.72

0.41

0.42

Kappa

0.69

0.48

0.59

0.15

0.15

Yoden index 0.75

0.50

0.61

0.22

0.23

295

296

Prediction of COVID-19 on CT images from pathogenic negative

297 patients.

298

Because high false negative results were frequently reported from nucleic

299 acid testing, we aimed to test whether the algorithm could detect COVID-19

300 when the pathogenic test came negative. To achieve this goal, we enrolled

301 additional 15 COVID-19 cases, in which initial two nucleic acid tests came

302 negative and for the third test they became positive. These CT results were

303 taken on the same day of the nucleic acid tests (Fig 5). Interestingly, we found

304 that, 46 out of the 54 images when nucleic acid test results were negative were

305 predicted as COVID-19 positive by the algorithm, with the accuracy of 85.2%.

306 These results indicate that the algorithm has high value serving as a screening

307 method for COVID-19.

18

medRxiv preprint doi: https://doi.org/10.1101/2020.02.14.20023028.this version posted April 24, 2020. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission.
308
309 Fig 5. Representative images from a COVID-19 patient with two negatively 310 reported nucleic acid tests at earlier stages and one final positively reported 311 test at a later stage. On the left, only one inflammatory lesion (blue arrow) can 312 be seen near diaphragm. In the middle, lesions (yellow arrows) were found in 313 two levels of images. On the right, the images were taken on the ninth day 314 after admission. The inflammation continued to progress, extending to both 315 lungs (red arrows), and the nucleic acid test became positive.
316
19

medRxiv preprint doi: https://doi.org/10.1101/2020.02.14.20023028.this version posted April 24, 2020. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission.

317

Discussion

318

Timely diagnosis and triaging of PUIs are crucial for the control of

319 emerging infectious diseases such as the current COVID-19. Due to the

320 limitation of nucleic acid -based laboratory testing, there is an urgent need to

321 look for fast alternative methods that can be used by front-line health care 322 personals for quickly and accurately diagnosing the disease. In the present 323 study, we have developed an AI program by analyzing representative CT

324 images using a deep learning method. This is a retrospective, multicohort, 325 diagnostic study using our modified Inception migration neuro network, which 326 has achieved an overall 89.5% accuracy. Moreover, the high performance of

327 the deep learning model we developed in this study was tested using external 328 samples with 79.3% accuracy. More importantly, as a screening method, our

329 model achieved a relative high sensitivity, 0.88 and 0.83 on internal and

330 external certain CT images datasets, respectively. Furthermore, the model 331 achieved a better profomance on a certain people, the accuracy up to 82.5%.

332 Of note, our model was used to distinguish between COVID-19 and other

333 typical viral penumonia, both of which have quite similar radiologic 334 characteristics. During current COVID-19 global pandemics, the CNN model

335 can potentially serve as a powerful tool for COVID-19 screening.

336

It is important to note that our model aims to distinguish between

337 COVID-19 and other typical viral pneumonia, both of which have similar

338 radiologic characteristics. We compared the performance of our model with

20

medRxiv preprint doi: https://doi.org/10.1101/2020.02.14.20023028.this version posted April 24, 2020. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission.

339 that of two skilled radiologists, and our model has shown much higher

340 accuracy and sensitivity. These findings have demonstrated the 341 proof-of-principle that deep learning can extract CT image features of 342 COVID-19 for diagnostic purposes. Using the supercomputer system, the time

343 for each case takes only about 10 seconds, and it can be performed remotely 344 via a shared public platform. Therefore, further developing this system can 345 significantly shorten the diagnosis time for disease control. Our study

346 represents the first study to apply artificial intelligence technologies to CT

347 images for effectively screening for COVID-19.

348

The gold standard for COVID-19 diagnosis has been nucleic acid based

349 detection for the existence of specific sequences of the SARS-COV-2 gene. 350 While we still value the importance of nucleic acid detection in the diagnosis of

351 SARS-COV-2 infection, we must also note that the high number of false

352 negatives due to several factors such as methodological disadvantages, 353 disease stages, and methods for specimen collection might delay diagnosis

354 and disease control. Recent data have suggested that the accuracy of nucleic

355 acid testing is only about 30-50% [6,7,8]. Using CT imaging feature extraction, 356 we are able to achieve above 89.5% accuracy, significantly outplaying nucleic

357 acid testing. More interestingly, testing CT images from COVID-19 patients

358 when initial pathogenic testing came negative, our model has achieved the 359 accuracy of 85.2% for correctly predicting COVID-19. According to a study

360 authored by Xia L et al, 75% patients with negative RT-PCR results had

21

medRxiv preprint doi: https://doi.org/10.1101/2020.02.14.20023028.this version posted April 24, 2020. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission.

361 positive CT findings [17]. The study recommended that chest CT as a primary

362 tool for the current COVID-19 detection in epidemic areas.

363

Deep learning methods have been used to solve data-rich biology and

364 medicine. A large number of labeled data is required for training [18]. Although

365 we are satisfied with the initial results, we believe that with more CT images 366 included in the training, we will achieve higher accuracy. Therefore, further 367 optimizing and testing this system is warranted. To achieve this, we have

368 generated a webpage that licensed healthcare personnel can access to upload 369 CT images for testing and validation. The webpage information is as following: 370 https://ai.nscc-tj.cn/thai/deploy/public/pneumonia_ct.

371

There are some limitations to our study. Although DL has been used to

372 represent and learn predictable relationships in many diverse forms of data,

373 and it holds promise for applications in precision medicine, many factors such

374 as low signal to noise and complex data integration have challenged the DL 375 efficacy [19]. CT images represent a difficult classification task due to the

376 relatively large number of variable objects, specifically the imaged areas

377 outside the lungs that are irrelevant to the diagnosis of pneumonia [12]. In 378 addition, the training data set is relatively small. The performance of this

379 system is expected to increase when the training volume is increased. It

380 should also be noted that, the features of the CT images we analyzed were 381 from patients with severe lung lesions at later stages of disease development.

382 Although we have enrolled 15 cases of COVID patients for assessing the value

22

medRxiv preprint doi: https://doi.org/10.1101/2020.02.14.20023028.this version posted April 24, 2020. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission.

383 of the algorithm for early diagnosis, larger numbers of database to associate

384 this with the disease progress and all pathologic stages of COVID-19 is

385 necessary to optimize the diagnostic system.

386

In future, we intend to link hierarchical features of CT images to features of

387 other factors such as genetic, epidemiological and clinical information for

388 multi-modeling analysis for an enhanced diagnosis. The artificial intelligence

389 system developed in our study should significantly contribute to COVID-19

390 disease control by reducing the number of PUIs for timely quarantine and

391 treatment.
392

23

medRxiv preprint doi: https://doi.org/10.1101/2020.02.14.20023028.this version posted April 24, 2020. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission.
393 Ethics Committee Approval and Patient Consent: This study complies with 394 the Institutional Review Board of each participating institutes. Informed 395 consent was exempted by the IRB because of the retrospective nature of this 396 study. 397 Funding Source: None 398 Competing interests: The authors have declared that no competing interest 399 exists 400 Abbreviations: 401 COVID-19, Corona Virus Disease 402 CT, Computed Tomography 403 SARS-COV-2, severe acute respiratory syndrome coronavirus 2Convolutional 404 CNN, Neural Network 405 ROI, region of interest 406 M-Inception, modified Inception 407 AUC, Area Under Curve 408 PPV, Positive predictive value 409 NPV, Negative predictive value 410 CV, computer vision
411 412
24

medRxiv preprint doi: https://doi.org/10.1101/2020.02.14.20023028.this version posted April 24, 2020. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission.

413

Reference

414 1. Zhou F, Yu T, Du R, Fan G, Liu Y, Liu Z, et al. Clinical course and risk factors

415 for mortality of adult inpatients with COVID-19 in Wuhan, China: a

416 retrospective cohort study. Lancet. Mar. 2020.

417 2. Velavan T, Meyer C. The COVID-19 epidemic. Trop Med Int Health, Mar 418 2020. 419 3. Wang D, Hu B, Hu C, Zhu F, Liu X, Zhang J, et al. Clinical Characteristics of

420 138 Hospitalized Patients With 2019 Novel Coronavirus-Infected Pneumonia 421 in Wuhan, China. JAMA. 2020 422 4. Chen N, Zhou M, Dong X, Qu J, Gong F, Han Y, et al. Epidemiological and

423 clinical characteristics of 99 cases of 2019 novel coronavirus pneumonia in 424 Wuhan, China: a descriptive study. Lancet. 2020.

425 5. Li Q, Guan X, Wu P, Wang X, Zhou L, Tong Y, et al. Early Transmission

426 Dynamics in Wuhan, China, of Novel Coronavirus-Infected Pneumonia. N Engl 427 J Med. Mar. 2020.

428 6. Huang C, Wang Y, Li X, Ren L, Zhao J, Hu Y, et al. Clinical features of

429 patients infected with 2019 novel coronavirus in Wuhan, China. Lancet. 2020. 430 7. Corman VM, Landt O, Kaiser M, Molenkamp R, Meijer A, Chu DK, et al.

431 Detection of 2019 novel coronavirus (2019-nCoV) by real-time RT-PCR. Euro

432 surveillance vol. 25, Jan. 2020. 433 8. Chu DKW, Pan Y, Cheng SMS, Hui KPY, Krishnan P, Liu Y, et al. Molecular

434 Diagnosis of a Novel Coronavirus (2019-nCoV) Causing an Outbreak of

25

medRxiv preprint doi: https://doi.org/10.1101/2020.02.14.20023028.this version posted April 24, 2020. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission.
435 Pneumonia. Clinical chemistry. 2020. 436 9. Zhang N, Wang L, Deng X, Liang R, Su M, He C, et al. Recent advances in 437 the detection of respiratory virus infection in humans. J Med Virol. 2020. 438 10.Chung M, Bernheim A, Mei X , Zhang N, Huang M, Zeng X, et al. CT 439 Imaging Features of 2019 Novel Coronavirus (2019-nCoV). Radiology. Apr. 440 2020. 441 11. Gomez P, Semmler M, Schutzenberger A, Bohr C, Dollinger M. Low-light 442 image enhancement of high-speed endoscopic videos using a convolutional 443 neural network. Med Biol Eng Comput. 2019; 57(7): 1451-63. 444 12. Choe J, Lee SM, Do KH, Lee G, Lee JG, Lee SM, et al. Deep 445 Learning-based Image Conversion of CT Reconstruction Kernels Improves 446 Radiomics Reproducibility for Pulmonary Nodules or Masses. Radiology. 2019; 447 292(2): 365-73. 448 13. Kermany DS, Goldbaum M, Cai W, Valentim CCS, Liang H, Baxter SL, et al. 449 Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep 450 Learning. Cell 2018; 172(5): 1122-31. 451 14. Negassi M, Suarez-Ibarrola R, Hein S, Miernik A, Reiterer A. Application of 452 artificial neural networks for automated analysis of cystoscopic images: a 453 review of the current status and future prospects. World J Urol. 2020. 454 15. Wang P, Xiao X, Glissen Brown JR, Berzin TM, Tu M, Xiong F, et al. 455 Development and validation of a deep-learning algorithm for the detection of 456 polyps during colonoscopy. Nat Biomed Eng. 2018; 2(10): 741-8.
26

medRxiv preprint doi: https://doi.org/10.1101/2020.02.14.20023028.this version posted April 24, 2020. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. All rights reserved. No reuse allowed without permission.
457 16. Koo HJ, Lim S, Choe J, Choi SH, Sung H, Do KH. Radiographic and CT 458 Features of Viral Pneumonia. Radiographics. 2018; 38(3): 719-39. 459 17. Ai T, Yang Z, Hou H, Zhan C, Chen C, Lv W, et al. Correlation of Chest CT 460 and RT-PCR Testing in Coronavirus Disease 2019 (COVID-19) in China: A 461 Report of 1014 Cases [published online ahead of print, 2020 Feb 26]. 462 Radiology. 2020; p.200642. 463 18. Ching T, Himmelstein DS, Beaulieu-Jones BK, Kalinin AA, Do BT, Way GP, et 464 al. Opportunities and obstacles for deep learning in biology and medicine. J R 465 Soc Interface. 2018;15(141):20170387. doi:10.1098/rsif.2017.0387 466 19. Grapov D, Fahrmann J, Wanichthanarak K, Khoomrung S. Rise of Deep 467 Learning for Genomic, Proteomic, and Metabolomic Data Integration in 468 Precision Medicine. OMICS. 2018;22(10):630–636.
469
27

