
close this message
Donate to arXiv

Please join the Simons Foundation and our generous member organizations in supporting arXiv during our giving campaign September 23-27. 100% of your contribution will fund improvements and new initiatives to benefit arXiv's global scientific community.
DONATE

[secure site, no need to create account]
Skip to main content
Cornell University
We gratefully acknowledge support from
the Simons Foundation and member institutions.
arXiv.org > eess > arXiv:2003.10769

Help | Advanced Search
Search
arXiv
Cornell University Logo
open search
GO
open navigation menu
quick links

    Login
    Help Pages
    About

Electrical Engineering and Systems Science > Image and Video Processing
arXiv:2003.10769 (eess)
COVID-19 e-print

Important: e-prints posted on arXiv are not peer-reviewed by arXiv; they should not be relied upon without context to guide clinical practice or health-related behavior and should not be reported in news media as established information without consulting multiple experts in the field.
[Submitted on 22 Mar 2020 ( v1 ), last revised 27 Mar 2020 (this version, v2)]
Title: Estimating Uncertainty and Interpretability in Deep Learning for Coronavirus (COVID-19) Detection
Authors: Biraja Ghoshal , Allan Tucker
Download PDF

    Abstract: Deep Learning has achieved state of the art performance in medical imaging. However, these methods for disease detection focus exclusively on improving the accuracy of classification or predictions without quantifying uncertainty in a decision. Knowing how much confidence there is in a computer-based medical diagnosis is essential for gaining clinicians trust in the technology and therefore improve treatment. Today, the 2019 Coronavirus (SARS-CoV-2) infections are a major healthcare challenge around the world. Detecting COVID-19 in X-ray images is crucial for diagnosis, assessment and treatment. However, diagnostic uncertainty in the report is a challenging and yet inevitable task for radiologist. In this paper, we investigate how drop-weights based Bayesian Convolutional Neural Networks (BCNN) can estimate uncertainty in Deep Learning solution to improve the diagnostic performance of the human-machine team using publicly available COVID-19 chest X-ray dataset and show that the uncertainty in prediction is highly correlates with accuracy of prediction. We believe that the availability of uncertainty-aware deep learning solution will enable a wider adoption of Artificial Intelligence (AI) in a clinical setting. 

Subjects: 	Image and Video Processing (eess.IV) ; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)
Cite as: 	arXiv:2003.10769 [eess.IV]
  	(or arXiv:2003.10769v2 [eess.IV] for this version)
Bibliographic data
[ Enable Bibex  ( What is Bibex? )]
Submission history
From: Biraja Ghoshal [ view email ]
[v1] Sun, 22 Mar 2020 21:58:13 UTC (1,284 KB)
[v2] Fri, 27 Mar 2020 16:48:13 UTC (1,414 KB)
Full-text links:
Download:

    PDF
    Other formats

( license )
Current browse context:
eess.IV
< prev   |   next >
new | recent | 2003
Change to browse by:
cs
cs.CV
cs.LG
eess
stat
stat.ML
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

Export citation
Bookmark
BibSonomy logo Mendeley logo Reddit logo ScienceWISE logo
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) Browse v0.3.2.5 released 2020-07-27    Feedback?

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

