<!DOCTYPE html> <html class="js flexbox canvas canvastext webgl touch geolocation postmessage no-websqldatabase indexeddb hashchange history draganddrop websockets rgba hsla multiplebgs backgroundsize borderimage borderradius boxshadow textshadow opacity cssanimations csscolumns cssgradients no-cssreflections csstransforms csstransforms3d csstransitions fontface generatedcontent video audio localstorage sessionstorage webworkers applicationcache svg inlinesvg smil svgclippaths" style><!--
 Page saved with SingleFileZ 
 url: http://papers.nips.cc/paper/8160-sanity-checks-for-saliency-maps 
 saved date: Sat Oct 31 2020 20:16:03 GMT+0400 (Arabian Standard Time)
--><meta charset=utf-8>
<meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1">
<title>Sanity Checks for Saliency Maps</title>
<meta name=citation_title content="Sanity Checks for Saliency Maps">
<meta name=citation_author content="Julius Adebayo">
<meta name=citation_author content="Justin Gilmer">
<meta name=citation_author content="Michael Muelly">
<meta name=citation_author content="Ian Goodfellow">
<meta name=citation_author content="Moritz Hardt">
<meta name=citation_author content="Been Kim">
<meta name=citation_publication_date content=2018>
<meta name=citation_conference_title content="Advances in Neural Information Processing Systems">
<meta name=citation_firstpage content=9505>
<meta name=citation_lastpage content=9515>
<meta name=citation_pdf_url content=http://papers.nips.cc/paper/8160-sanity-checks-for-saliency-maps.pdf>
<meta name=description content="Electronic Proceedings of Neural Information Processing Systems">
<meta name=viewport content="width=device-width">
<link rel=stylesheet href=stylesheet_0.css>
<link rel=stylesheet href=stylesheet_1.css>
<style>#MathJax_Message{position:fixed;left:1px;bottom:2px;background-color:#E6E6E6;border:1px solid #959595;margin:0px;padding:2px 8px;z-index:102;color:black;font-size:80%;width:auto;white-space:nowrap}</style><link type=image/x-icon rel="shortcut icon" href=images/0.ico><style>.sf-hidden{display:none!important}</style><link rel=canonical href=http://papers.nips.cc/paper/8160-sanity-checks-for-saliency-maps></head>
 <body><div id=MathJax_Message style=display:none></div>
 <!--[if lt IE 7]>
            <p class="chromeframe">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> or <a href="http://www.google.com/chromeframe/?redirect=true">activate Google Chrome Frame</a> to improve your experience.</p>
        <![endif]-->
 <div class=header-container>
 <header class="wrapper clearfix">
 
 <h1 class=sitename><a href=http://papers.nips.cc/>NIPS Proceedings</a><sup>β</sup></h1>
 
 
 <form action=/search/ class=search>
 <input name=q value class=search placeholder=search>
 </form>
 
 <nav>
 <ul>
 
 
 <li><a href=http://papers.nips.cc/>Books</a></li>
 
 <li><a href=http://papers.nips.cc/book/advances-in-neural-information-processing-systems-31-2018>2018</a></li>
 </ul>
 </nav>
 </header>
 </div>
 <div class=main-container>
 <div class="main wrapper clearfix">
 
<h2 class=subtitle>Sanity Checks for Saliency Maps</h2>
 
 
<p>Part of: <a href=http://papers.nips.cc/book/advances-in-neural-information-processing-systems-31-2018>Advances in Neural Information Processing Systems 31 (NIPS 2018)</a></p>
 <a href=http://papers.nips.cc/paper/8160-sanity-checks-for-saliency-maps.pdf>[PDF]</a>
 <a href=http://papers.nips.cc/paper/8160-sanity-checks-for-saliency-maps/bibtex>[BibTeX]</a>
 <a href=http://papers.nips.cc/paper/8160-sanity-checks-for-saliency-maps-supplemental.zip>[Supplemental]</a>
 <a href=http://media.nips.cc/nipsbooks/nipspapers/paper_files/nips31/reviews/5780.html>[Reviews]</a>
<h3>Authors</h3>
<ul class=authors>
 
 <li class=author><a href=http://papers.nips.cc/author/julius-adebayo-12168>Julius Adebayo</a></li>
 
 <li class=author><a href=http://papers.nips.cc/author/justin-gilmer-10304>Justin Gilmer</a></li>
 
 <li class=author><a href=http://papers.nips.cc/author/michael-muelly-12169>Michael Muelly</a></li>
 
 <li class=author><a href=http://papers.nips.cc/author/ian-goodfellow-4369>Ian Goodfellow</a></li>
 
 <li class=author><a href=http://papers.nips.cc/author/moritz-hardt-5305>Moritz Hardt</a></li>
 
 <li class=author><a href=http://papers.nips.cc/author/been-kim-7252>Been Kim</a></li>
 
</ul>
<h3>Conference Event Type: Poster</h3>
<h3>Abstract</h3>
<p class=abstract>Saliency methods have emerged as a popular tool to highlight features in an input
deemed relevant for the prediction of a learned model. Several saliency methods
have been proposed, often guided by visual appeal on image data. In this work, we
propose an actionable methodology to evaluate what kinds of explanations a given
method can and cannot provide. We find that reliance, solely, on visual assessment
can be misleading. Through extensive experiments we show that some existing
saliency methods are independent both of the model and of the data generating
process. Consequently, methods that fail the proposed tests are inadequate for
tasks that are sensitive to either data or model, such as, finding outliers in the data,
explaining the relationship between inputs and outputs that the model learned,
and debugging the model. We interpret our findings through an analogy with
edge detection in images, a technique that requires neither training data nor model.
Theory in the case of a linear model and a single-layer convolutional neural network
supports our experimental findings.</p>
 
 <aside>
 <h3>Neural Information Processing Systems (NIPS)</h3>
 <p>Papers published at the Neural Information Processing Systems Conference.</p>
 </aside>
 
 </div> 
 </div> 
 <div class=footer-container>
 <footer class=wrapper>
 
 <h3>© 1987 – 2020 Neural Information Processing Systems Foundation, Inc.</h3>
 
 </footer>
 </div>
 
 
 
 
 
<link rel=stylesheet type=text/css href=stylesheet_2.css class=sf-hidden>
 
 
 
 
 
